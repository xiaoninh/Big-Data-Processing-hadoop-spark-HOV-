{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 - Higher Order Functions (10 pts)\n",
    "\n",
    "In this homework, we will practice Python's higher order functions. Please note that you may only use higher order functions **without access to global variables**. Your expression should contain only **map()**, **filter()**, **sorted**, **reduce()** and your custom functions.\n",
    "\n",
    "You are required to turn in this notebook with all the parts filled in between <>. Your notebook must be named BDM\\_HW2\\_HOF_NetID.ipynb.\n",
    "\n",
    "We will be using the provided the Graduation Outcomes data set for cohorts from 2001 through 2006 (Classes of 2005 through 2010) from the NYC Department of Education (the data handle on NYC Open Data is **avir-tzek**). The data is available on online as **nyc_grads.csv**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The first ten records of the data are shown below. Please note, the data are sorted by \"Demographics\", then \"Borough\", then \"Cohort\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 (3 points)\n",
    "\n",
    "In this data set, we would like to inspect whether there is a correlation between the dropped out percentage and the percentage of students graduated with advanced regents for schools in NYC. Thus, we must compute the ratio of **Dropped Out** and **Advanced Regents** for each borough, and for each year by dividing them by the **Total Cohort** value. Thus, the only useful records for us are those with the **Demographic** value equals to **'Borough Total'**, aka. you must filter the data to this type of demographic first.\n",
    "\n",
    "Please complete the HOF expression below to transform each input record into a tuple of only 4 elements: **Borough**, **Cohort**, **Ratio_Advanced**, **Ratio_Dropped**. Note that, your expression must user **reader** as input. Though you are encouraged to write your helper functions (instead of lambdas) to make your expression concise, global variables are absolutely not allowed. No exception. The output must be exactly as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bronx', '2001', 0.08713874094123811, 0.21286999039552956),\n",
       " ('Bronx', '2002', 0.08244680851063829, 0.1778590425531915),\n",
       " ('Bronx', '2003', 0.09206279342723005, 0.1813380281690141),\n",
       " ('Bronx', '2004', 0.09711779448621553, 0.16033138401559455),\n",
       " ('Bronx', '2005', 0.10174629324546952, 0.1414827018121911),\n",
       " ('Bronx', '2006', 0.10000641889723345, 0.1541819115475961),\n",
       " ('Brooklyn', '2001', 0.14172636641450828, 0.1776965081909724),\n",
       " ('Brooklyn', '2002', 0.1376874279123414, 0.16190888119953864),\n",
       " ('Brooklyn', '2003', 0.15182338051935876, 0.14990156557607576),\n",
       " ('Brooklyn', '2004', 0.1673600858945108, 0.13300228157294322),\n",
       " ('Brooklyn', '2005', 0.16201692714164168, 0.11544489722806861),\n",
       " ('Brooklyn', '2006', 0.1676060783694819, 0.12314560129864274),\n",
       " ('Manhattan', '2001', 0.14609313338595106, 0.1548539857932123),\n",
       " ('Manhattan', '2002', 0.13904776052885687, 0.1294659436975414),\n",
       " ('Manhattan', '2003', 0.18207363642913754, 0.1245766986094099),\n",
       " ('Manhattan', '2004', 0.18582666754809282, 0.12176902227804588),\n",
       " ('Manhattan', '2005', 0.1687180458246544, 0.10080161585558291),\n",
       " ('Manhattan', '2006', 0.16940789473684212, 0.10258284600389864),\n",
       " ('Queens', '2001', 0.15836811474927986, 0.15848568573276114),\n",
       " ('Queens', '2002', 0.15534990691052458, 0.15419997809659403),\n",
       " ('Queens', '2003', 0.18436057561770297, 0.14759706760792832),\n",
       " ('Queens', '2004', 0.19246995994659546, 0.13377837116154873),\n",
       " ('Queens', '2005', 0.1854338578237917, 0.12480139408538773),\n",
       " ('Queens', '2006', 0.18595970958175684, 0.11534921771142244),\n",
       " ('Staten Island', '2001', 0.2262396694214876, 0.10769628099173553),\n",
       " ('Staten Island', '2002', 0.20827285921625543, 0.10304789550072568),\n",
       " ('Staten Island', '2003', 0.20934091986723566, 0.08866761498340446),\n",
       " ('Staten Island', '2004', 0.248430709802028, 0.09198454852728151),\n",
       " ('Staten Island', '2005', 0.2374439461883408, 0.08116591928251121),\n",
       " ('Staten Island', '2006', 0.25896154681729305, 0.08994134260265045)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mapper_ratios(reader):\n",
    "    adv_ratio = int(reader['Advanced Regents'])/int(reader['Total Cohort'])\n",
    "    drop_ratio = int(reader['Dropped Out'])/int(reader['Total Cohort'])\n",
    "    \n",
    "    return (reader['Borough'],reader['Cohort'],adv_ratio,drop_ratio)\n",
    "\n",
    "with open('nyc_grads.csv', 'r') as fi:\n",
    "    reader = csv.DictReader(fi)\n",
    "    output1 =list(map(mapper_ratios,filter(lambda x: x['Demographic']=='Borough Total', reader)))\n",
    "\n",
    "output1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 2 (3 points)\n",
    "\n",
    "Now given *output1* from Task 1, we need to compute the average ratio of dropped out and advanced regents per borough (i.e. averaging the numbers from 2001 to 2006 for each borough). Please complete the HOF expression below. Your output should be similar to the one provided. Your input is **output1**.\n",
    "\n",
    "Note: If you could not finish Task 1, you could use the output information above as input to your Task 2. Please try to use the least memory possible for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bronx', 0.0934198082513375, 0.17134384308218617),\n",
       " ('Brooklyn', 0.15470337770864048, 0.14351662251104022),\n",
       " ('Manhattan', 0.16519452307558916, 0.1223416853729485),\n",
       " ('Queens', 0.1769903541049419, 0.13903528573260707),\n",
       " ('Staten Island', 0.23144827521877342, 0.09375060031471814)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reducer_sum_all(d,output1):\n",
    "    if output1[0] not in d.keys(): \n",
    "        d[output1[0]]=[output1[2],output1[3]]\n",
    "    else:\n",
    "        d[output1[0]][0]+=output1[2]\n",
    "        d[output1[0]][1]+=output1[3]\n",
    "    return d\n",
    "\n",
    "output2 = list(map(lambda d:(d[0],d[1][0]/6,d[1][1]/6),reduce(reducer_sum_all, output1, {}).items()))\n",
    "\n",
    "output2  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "## Task 3 (4 points)\n",
    "\n",
    "In this task, you are asked to complete Homework 1 using only map(), filter(), reduce(), and/or sorted() higher-order functions. Note that, instead of writing to a CSV file, the output can be printed in the notebook, similar to what presented below (some differences in the output format are tolerable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P02291 16 1181.97\n",
      "P19498 17 989.99\n",
      "P32565 17 1006.09\n",
      "P33162 18 1210.92\n",
      "P39328 17 1129.01\n",
      "P58225 17 1349.82\n",
      "P61235 18 959.02\n",
      "P76615 18 1087.96\n",
      "P82222 17 950.05\n",
      "P92449 14 966.17\n"
     ]
    }
   ],
   "source": [
    "def reducer (d,i):\n",
    "    if i['Product ID']not in d.keys():\n",
    "        customers = set()\n",
    "        customers.add(i['Customer ID'])\n",
    "        d[i['Product ID']]=[1,float(i['Item Cost']),customers]\n",
    "    else:\n",
    "        d[i['Product ID']][1]+=float(i['Item Cost'])\n",
    "        if i['Customer ID'] not in d[i['Product ID']][2]:\n",
    "            d[i['Product ID']][0]+=1\n",
    "            d[i['Product ID']][2].add(i['Customer ID'])           \n",
    "    return d\n",
    "\n",
    "def mapper(dic):\n",
    "    print (dic[0],dic[1][0],round(dic[1][1], 2))\n",
    "    return (dic[0],dic[1][0],round(dic[1][1], 2))\n",
    "\n",
    "\n",
    "with open('sale.csv', 'r') as fi:\n",
    "    reader = csv.DictReader(fi)\n",
    "    output3 = list(map(mapper,sorted(reduce(reducer,reader,{}).items())))\n",
    "    \n",
    "#output3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('P02291', 16, 1181.97),\n",
       " ('P19498', 17, 989.99),\n",
       " ('P32565', 17, 1006.09),\n",
       " ('P33162', 18, 1210.92),\n",
       " ('P39328', 17, 1129.01),\n",
       " ('P58225', 17, 1349.82),\n",
       " ('P61235', 18, 959.02),\n",
       " ('P76615', 18, 1087.96),\n",
       " ('P82222', 17, 950.05),\n",
       " ('P92449', 14, 966.17)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
